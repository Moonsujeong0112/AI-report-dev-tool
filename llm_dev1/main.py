import os
from typing import List
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

from fastapi import FastAPI, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import Response, FileResponse
from fastapi import Request
from llm_dev1.schemas import ChatRequest, ChatResponse, UsageStats, ChatHistoryItem
from llm_dev1 import llm_provider
from llm_dev1.usage_tracker import usage_tracker
from llm_dev1.rag_engine import build_prompt
from llm_dev1.guardrail import contains_profanity
from llm_dev1.llm_provider import chat as gemini_chat



app = FastAPI(
    title="LLM FastAPI (Gemini)",
    version="0.1.0",
    description="FastAPI backend for Google Gemini API with usage tracking.",
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/api/history")
def get_chat_history(limit: int = 100):
    return usage_tracker.get_history(limit=limit)

@app.get("/favicon.ico")
def get_favicon():
    """íŒŒë¹„ì½˜ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    # ê°„ë‹¨í•œ SVG íŒŒë¹„ì½˜ì„ ë°˜í™˜
    svg_content = '''<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100">
        <circle cx="50" cy="50" r="45" fill="#667eea"/>
        <text x="50" y="65" font-size="50" text-anchor="middle" fill="white">ğŸ¤–</text>
    </svg>'''
    return Response(content=svg_content, media_type="image/svg+xml")

@app.get("/health")
def health():
    return {
        "status": "ok",
        "provider": os.getenv("PROVIDER", "gemini"),
        "model": os.getenv("GEMINI_MODEL", "gemini-2.5-flash"),
        "env": os.getenv("APP_ENV", "dev"),
        "has_api_key": bool(os.getenv("GEMINI_API_KEY")),
        "api_key_length": len(os.getenv("GEMINI_API_KEY", "")),
        "api_key_preview": os.getenv("GEMINI_API_KEY", "")[-4:] if os.getenv("GEMINI_API_KEY") else "None"
    }

@app.get("/debug/env")
def debug_env():
    """í™˜ê²½ ë³€ìˆ˜ ë””ë²„ê¹… ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return {
        "PROVIDER": os.getenv("PROVIDER"),
        "GEMINI_MODEL": os.getenv("GEMINI_MODEL"),
        "GEMINI_API_KEY": "***" + os.getenv("GEMINI_API_KEY", "")[-4:] if os.getenv("GEMINI_API_KEY") else None,
        "APP_ENV": os.getenv("APP_ENV"),
        "PYTHONPATH": os.getenv("PYTHONPATH"),
        "current_working_dir": os.getcwd(),
        "files_in_current_dir": os.listdir(".") if os.path.exists(".") else []
    }

@app.post("/chat", response_model=ChatResponse)
def chat(req: ChatRequest):
    # 1. ìµœì‹  user ë©”ì‹œì§€ë§Œ ì¶”ì¶œ (í•­ìƒ ì¡´ì¬í•œë‹¤ê³  ê°€ì •)
    latest_msg = req.messages[-1]

    # 2. RAG ë¯¸ì‚¬ìš©ì´ë¯€ë¡œ system ë©”ì‹œì§€ëŠ” ì œê±°í•˜ê³  ì§ˆë¬¸ë§Œ ë„˜ê¹€
    cleaned_messages = [
        m for m in req.messages
        if m.role == "user" or m.role == "assistant"
    ]

    # (ì„ íƒ) ë§Œì•½ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë§Œ ë³´ë‚´ê³  ì‹¶ë‹¤ë©´ ì´ë ‡ê²Œë„ ê°€ëŠ¥:
    # cleaned_messages = [latest_msg]

    # 3. LLMì— ì „ë‹¬
    result = llm_provider.chat(
        messages=[{"role": m.role, "content": m.content} for m in cleaned_messages],
        temperature=req.temperature,
        max_tokens=req.max_tokens
    )
    return ChatResponse(**result)

@app.get("/usage/stats", response_model=UsageStats)
def get_usage_stats():
    """ì‚¬ìš©ëŸ‰ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return usage_tracker.get_stats()

@app.get("/usage/history", response_model=List[ChatHistoryItem])
def get_chat_history(limit: int = 50):
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return usage_tracker.get_history(limit=limit)

@app.get("/usage/reset")
def reset_usage_stats():
    """ì‚¬ìš©ëŸ‰ í†µê³„ë¥¼ ë¦¬ì…‹í•©ë‹ˆë‹¤. (ê°œë°œìš©)"""
    # ì‹¤ì œë¡œëŠ” ê´€ë¦¬ì ê¶Œí•œ í™•ì¸ì´ í•„ìš”
    usage_tracker.stats.total_requests = 0
    usage_tracker.stats.total_tokens_input = 0
    usage_tracker.stats.total_tokens_output = 0
    usage_tracker.stats.total_cost = 0.0
    usage_tracker.stats.requests_today = 0
    usage_tracker.stats.tokens_today = 0
    usage_tracker.stats.cost_today = 0.0
    usage_tracker.stats.last_request_time = None
    usage_tracker._save_stats()
    return {"message": "Usage stats reset successfully"}

@app.post("/rag-test")
def rag_prompt_test(
    metadata: str = Form(...),
    chat_log: str = Form(...),
    rag_criteria: str = Form(...),
    user_input: str = Form(...),
    temperature: float = Form(0.7),
    max_tokens: int = Form(1000),
):
    if contains_profanity(user_input):
        return JSONResponse(status_code=400, content={"error": "ì…ë ¥ì— ê¸ˆì§€ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."})

    full_prompt = build_prompt(metadata, chat_log, rag_criteria, user_input)

    result = gemini_chat(
        messages=[{"role": "user", "content": full_prompt}],
        temperature=temperature,
        max_tokens=max_tokens
    )

    return {
        "prompt": full_prompt,
        "response": result["content"],
        "tokens_input": result["tokens_input"],
        "tokens_output": result["tokens_output"],
        "cost": result["cost"]
    }
    
# âœ… ì‚¬ìš©ëŸ‰ í†µê³„ ë°˜í™˜ API
@app.get("/api/stats")
def get_stats():
    """usage_stats.json íŒŒì¼ ë‚´ìš© ë°˜í™˜"""
    return usage_tracker.get_stats().dict()

# âœ… ëŒ€í™” íˆìŠ¤í† ë¦¬ ë°˜í™˜ API
@app.get("/api/history")
def get_history(limit: int = 100):
    """chat_history.json íŒŒì¼ ë‚´ìš© ë°˜í™˜ (ìµœëŒ€ Nê°œ)"""
    history = usage_tracker.get_history(limit=limit)
    return [item.dict() for item in history]

# ì •ì  íŒŒì¼ ì œê³µ (API ì—”ë“œí¬ì¸íŠ¸ ë’¤ì— ë°°ì¹˜)
app.mount("/static", StaticFiles(directory="llm_dev1/static"), name="static")

@app.get("/")
async def read_index():
    """ë£¨íŠ¸ ê²½ë¡œì—ì„œ index.htmlì„ ì œê³µí•©ë‹ˆë‹¤."""
    return FileResponse("llm_dev1/static/index.html")

