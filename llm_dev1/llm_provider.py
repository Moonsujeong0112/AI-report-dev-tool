import os
from typing import List, Dict, Any, Optional
import google.generativeai as genai
from .usage_tracker import usage_tracker

PROVIDER = os.getenv("PROVIDER", "gemini")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.5-flash")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# SDK ì´ˆê¸°í™”
if PROVIDER == "gemini":
    if not GEMINI_API_KEY:
        raise RuntimeError("GEMINI_API_KEY is not set")
    genai.configure(api_key=GEMINI_API_KEY)
    try:
        _model = genai.GenerativeModel(GEMINI_MODEL)
        print(f"âœ… Gemini ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {GEMINI_MODEL}")
    except Exception as e:
        print(f"âŒ Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise

def _to_gemini_contents(messages: List[Dict[str, str]]) -> List[Dict[str, Any]]:
    contents = []
    for m in messages:
        g_role = "model" if m.get("role") == "assistant" else "user"
        contents.append({"role": g_role, "parts": [m.get("content", "")]})
    return contents

def _count_tokens(text: str) -> int:
    """Gemini ê³µì‹ í† í¬ë‚˜ì´ì € ì‚¬ìš©"""
    try:
        return _model.count_tokens(text).total_tokens
    except Exception as e:
        print(f"âš ï¸ í† í° ê³„ì‚° ì‹¤íŒ¨ (fallback ì‚¬ìš©): {e}")
        return len(text) // 2

def _extract_text(candidate) -> str:
    try:
        content = getattr(candidate, 'content', None)
        if content and hasattr(content, 'parts') and content.parts:
            return "".join(part.text for part in content.parts if hasattr(part, "text") and part.text)
        elif content and hasattr(content, 'text') and content.text:
            return content.text
    except Exception as e:
        print(f"âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    return ""

def _describe_finish_reason(reason_code: int) -> str:
    return {
        0: "ë¯¸ì§€ì •",
        1: "ì •ìƒ ì™„ë£Œ",
        2: "MAX_TOKENS (ìµœëŒ€ í† í° ìˆ˜ ë„ë‹¬)",
        3: "SAFETY (ì•ˆì „ì„± ìœ„ë°˜)",
        4: "RECITATION (ë³µì‚¬/ë¶™ì—¬ë„£ê¸° ê°ì§€)",
        5: "ê¸°íƒ€ ì˜¤ë¥˜"
    }.get(reason_code, f"ì•Œ ìˆ˜ ì—†ìŒ ({reason_code})")

def chat(
    messages: List[Dict[str, str]],
    temperature: float = 0.7,
    max_tokens: Optional[int] = None,
) -> Dict[str, str]:
    if PROVIDER != "gemini":
        raise RuntimeError("Only 'gemini' provider is supported in this setup.")

    try:
        contents = _to_gemini_contents(messages)
        max_tokens = min(max_tokens or 512, 10000)
        gen_cfg = {
            "temperature": temperature,
            "max_output_tokens": max_tokens
        }

        # ì…ë ¥ í…ìŠ¤íŠ¸ í† í° ê³„ì‚°
        input_text = " ".join([m.get("content", "") for m in messages])
        tokens_input = _count_tokens(input_text)

        print(f"ğŸ” Gemini API ìš”ì²­:")
        print(f"   ëª¨ë¸: {GEMINI_MODEL}")
        print(f"   ì…ë ¥ í† í°: {tokens_input}")
        print(f"   ì„¤ì •: {gen_cfg}")

        resp = _model.generate_content(contents=contents, generation_config=gen_cfg)

        out_text = ""
        finish_reason = None

        if resp.candidates:
            candidate = resp.candidates[0]
            finish_reason = getattr(candidate, "finish_reason", None)
            print(f"ğŸ“¤ Gemini ì‘ë‹µ ë¶„ì„: finish_reason = {finish_reason} ({_describe_finish_reason(finish_reason)})")

            out_text = _extract_text(candidate).strip()
            tokens_output = _count_tokens(out_text)

            if finish_reason == 2 and tokens_output >= 50:
                out_text += "\n\nâš ï¸ ì‘ë‹µì´ ê¸¸ì–´ ì¤‘ê°„ì— ì˜ë ¸ì„ ìˆ˜ ìˆì–´ìš”."
            elif finish_reason == 2 and tokens_output < 50:
                print("âš ï¸ MAX_TOKENS ë°˜í™˜ë˜ì—ˆì§€ë§Œ ì‘ë‹µì´ ì§§ì•„ ì•ˆë‚´ë¬¸ ìƒëµ")
            elif finish_reason == 3:
                out_text = "âš ï¸ ì•ˆì „ ì •ì±…ì— ì˜í•´ ì‘ë‹µì´ ì°¨ë‹¨ëìŠµë‹ˆë‹¤."
            elif finish_reason == 4:
                out_text = "âš ï¸ ë³µì‚¬ëœ ì½˜í…ì¸ ê°€ ê°ì§€ë¼ ì‘ë‹µì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤."
            elif finish_reason == 5:
                out_text += "\n\nâš ï¸ Gemini ì‘ë‹µ ì˜¤ë¥˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."

        if not out_text:
            out_text = "âš ï¸ Geminiê°€ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”."
            tokens_output = 0

        cost = usage_tracker.estimate_cost(tokens_input, tokens_output)

        usage_tracker.record_chat(
            user_message=messages[-1].get("content", "") if messages else "",
            assistant_message=out_text,
            tokens_input=tokens_input,
            tokens_output=tokens_output,
            cost=cost,
        )

        print(f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ: ì¶œë ¥ í† í°={tokens_output}, ë¹„ìš©=${cost:.6f}")

        return {
            "content": out_text,
            "model": GEMINI_MODEL,
            "provider": "gemini",
            "tokens_input": tokens_input,
            "tokens_output": tokens_output,
            "cost": cost,
        }

    except Exception as e:
        print(f"âŒ Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e} ({type(e).__name__})")
        return {
            "content": f"ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ({e})",
            "model": GEMINI_MODEL,
            "provider": "gemini",
            "tokens_input": 0,
            "tokens_output": 0,
            "cost": 0.0,
        }
